# ğŸ¯ ImplementaÃ§Ã£o de Forced Alignment - SumÃ¡rio

## ğŸ“‹ Resumo das MudanÃ§as

Este documento resume todas as alteraÃ§Ãµes implementadas para adicionar suporte a **forced alignment** (alinhamento palavra-por-palavra) no projeto MMS-TTS API.

---

## ğŸ”§ Arquivos Modificados

### 1. **`app/word_alignment.py`** â­ PRINCIPAL

**Nova funÃ§Ã£o: `forced_align_audio_to_text()`**

Implementa o algoritmo de forced alignment usando Whisper em modo determinÃ­stico:

```python
def forced_align_audio_to_text(
    audio_path: str,
    original_text: str,
    language: str = "he",
    normalize_audio: bool = True
) -> Tuple[List[Dict], float]:
```

**CaracterÃ­sticas:**
- âœ… Usa `initial_prompt` com o texto original (forÃ§a Whisper a seguir o texto)
- âœ… ConfiguraÃ§Ã£o determinÃ­stica: `temperature=0`, `beam_size=1`
- âœ… Word timestamps ativados: `word_timestamps=True`
- âœ… Sem VAD (Voice Activity Detection) para evitar cortes
- âœ… PrÃ©-processamento de Ã¡udio (normalizaÃ§Ã£o, mono, 16kHz)
- âœ… Fallback inteligente para timestamps estimados

**ParÃ¢metros:**
- `audio_path`: Caminho do arquivo de Ã¡udio (MP3/WAV)
- `original_text`: Texto original (FONTE DA VERDADE)
- `language`: CÃ³digo Whisper ('he', 'el', 'pt')
- `normalize_audio`: Se True, prÃ©-processa Ã¡udio

**Retorno:**
```python
(word_timestamps, audio_duration)
```

**Estrutura de `word_timestamps`:**
```json
[
  {
    "text": "×‘Ö°Ö¼×¨Öµ××©Ö´××™×ª",
    "start": 0.0,
    "end": 0.82,
    "textStart": 0,
    "textEnd": 9,
    "confidence": 1.0
  }
]
```

---

### 2. **`app/multi_model_api.py`** â­ PRINCIPAL

**Novo endpoint: `/speak_sync`**

```python
@app.post("/speak_sync")
async def speak_with_word_alignment(
    text: str = Form(...),
    model: str = Form("hebrew"),
    speed: float = Form(1.0),
    output_format: str = Form("mp3"),
    return_audio: bool = Form(True),
    user = Depends(get_rate_limited_user)
):
```

**Fluxo de processamento:**

1. **GeraÃ§Ã£o de Ã¡udio** (Sherpa-ONNX/MMS-TTS)
   - Converte texto em Ã¡udio de alta qualidade
   - Salva WAV temporÃ¡rio para Whisper

2. **Forced alignment** (Whisper)
   - Executa `forced_align_audio_to_text()`
   - ObtÃ©m timestamps palavra-por-palavra

3. **ConversÃ£o de formato**
   - MP3 ou WAV conforme solicitado
   - Base64 ou arquivo em cache

4. **Resposta JSON completa**
   - Ãudio (base64 ou URL)
   - Timestamps por palavra
   - EstatÃ­sticas de alinhamento
   - Tempos de processamento

**Exemplo de resposta:**
```json
{
  "text": "×‘Ö°Ö¼×¨Öµ××©Ö´××™×ª ×‘Ö¸Ö¼×¨Ö¸× ×Ö±×œÖ¹×”Ö´×™×",
  "model": "hebrew",
  "speed": 1.0,
  "audio_duration": 2.45,
  "audio_base64": "SUQzBAAAAAAAI1RTU0U...",
  "word_timestamps": [...],
  "alignment_stats": {
    "total_words": 3,
    "matched_words": 3,
    "match_ratio": 1.0
  },
  "processing_time": {
    "tts_seconds": 0.15,
    "alignment_seconds": 1.23,
    "total_seconds": 1.38
  }
}
```

**ModificaÃ§Ãµes adicionais:**
- Import do mÃ³dulo `word_alignment`
- InicializaÃ§Ã£o do Whisper no `startup_event()`
- VerificaÃ§Ã£o de disponibilidade (`WORD_ALIGNMENT_AVAILABLE`)

---

## ğŸ“„ Arquivos Criados

### 3. **`FORCED_ALIGNMENT.md`** ğŸ“–

DocumentaÃ§Ã£o completa do recurso:

- ğŸ“– VisÃ£o geral do forced alignment
- ğŸ¯ CaracterÃ­sticas e diferenÃ§as vs ASR
- ğŸ“¡ EspecificaÃ§Ã£o completa do endpoint
- ğŸ”§ ConfiguraÃ§Ã£o de variÃ¡veis de ambiente
- ğŸ§ª Exemplos de cÃ³digo (Python, JavaScript)
- ğŸ¨ Casos de uso prÃ¡ticos
- âš ï¸ Troubleshooting e dicas
- ğŸ“Š Performance esperada

**SeÃ§Ãµes principais:**
1. Modo determinÃ­stico
2. Alinhamento robusto
3. OtimizaÃ§Ã£o para CPU
4. Endpoint `/speak_sync`
5. ConfiguraÃ§Ã£o (Oracle vs Local)
6. Casos de uso (highlight, legendas, anÃ¡lise)

---

### 4. **`test_forced_alignment.py`** ğŸ§ª

Script completo de testes:

**Casos de teste:**
1. **Hebraico**: GÃªnesis 1:1
2. **Grego**: JoÃ£o 1:1
3. **PortuguÃªs**: Salmo 23:1

**Funcionalidades:**
- âœ… Health check da API
- âœ… Teste de cada idioma
- âœ… AnÃ¡lise de qualidade (match_ratio)
- âœ… IdentificaÃ§Ã£o de palavras problemÃ¡ticas
- âœ… GeraÃ§Ã£o de arquivos:
  - MP3 (Ã¡udio)
  - JSON (timestamps completos)
  - SRT (legendas)

**Como usar:**
```bash
python test_forced_alignment.py
```

**Output:**
```
test_output/
â”œâ”€â”€ hebrew_genesis.mp3
â”œâ”€â”€ hebrew_genesis_timestamps.json
â”œâ”€â”€ hebrew_genesis.srt
â”œâ”€â”€ greek_john.mp3
â”œâ”€â”€ greek_john_timestamps.json
â”œâ”€â”€ greek_john.srt
â”œâ”€â”€ portuguese_psalm.mp3
â”œâ”€â”€ portuguese_psalm_timestamps.json
â””â”€â”€ portuguese_psalm.srt
```

---

### 5. **`demo_forced_alignment.html`** ğŸ¨

Demo interativo completo:

**CaracterÃ­sticas:**
- ğŸ¨ Interface moderna e responsiva
- ğŸ¯ Highlight palavra-por-palavra em tempo real
- ğŸµ Player de Ã¡udio integrado
- ğŸ“Š EstatÃ­sticas visuais de alinhamento
- ğŸ–±ï¸ Click em palavras para pular para o timestamp
- ğŸŒ Suporte RTL (hebraico) e LTR (grego/portuguÃªs)

**Como usar:**
1. Abrir no navegador
2. Inserir texto (hebraico, grego ou portuguÃªs)
3. Selecionar idioma
4. Ajustar velocidade
5. Clicar "Generate & Align"
6. Assistir o highlight sincronizado!

**Tecnologias:**
- HTML5 + CSS3
- Vanilla JavaScript (sem dependÃªncias)
- Fetch API
- Web Audio API

---

## ğŸ”‘ Conceitos-Chave

### Forced Alignment vs ASR

| Aspecto | ASR Tradicional | Forced Alignment |
|---------|-----------------|------------------|
| **Objetivo** | Reconhecer texto desconhecido | Obter timestamps de texto conhecido |
| **Entrada** | Apenas Ã¡udio | Ãudio + texto original |
| **SaÃ­da** | Texto transcrito | Timestamps alinhados ao texto original |
| **CorreÃ§Ãµes** | Sim (corrige erros) | NÃ£o (mantÃ©m texto original) |
| **Use case** | TranscriÃ§Ã£o | SincronizaÃ§Ã£o, karaoke, anÃ¡lise |

### Modo DeterminÃ­stico

ConfiguraÃ§Ãµes que garantem resultados **reproduzÃ­veis**:

```python
model.transcribe(
    audio_path,
    temperature=0.0,      # Zero aleatoriedade
    beam_size=1,          # Busca gulosa (sem exploraÃ§Ã£o)
    initial_prompt=text,  # ForÃ§a seguir o texto
    word_timestamps=True  # Timestamps por palavra
)
```

### Alinhamento Robusto

O algoritmo `fuzzy_match_words()` lida com variaÃ§Ãµes do Whisper:

1. **NormalizaÃ§Ã£o multilÃ­ngue**
   - Remove niqqud hebraico
   - Remove acentos gregos/portugueses
   - Converte para lowercase

2. **Fuzzy matching**
   - Match exato: 1.0
   - Similaridade >= 0.55: aceito
   - SequÃªncia: evita matches fora de ordem

3. **Fallback inteligente**
   - Se match_ratio < 50%: timestamps estimados
   - DistribuiÃ§Ã£o proporcional ao comprimento
   - ConfianÃ§a = 0.3 (baixa)

---

## ğŸš€ Fluxo de ExecuÃ§Ã£o

### 1. RequisiÃ§Ã£o HTTP
```
POST /speak_sync
- text: "×‘Ö°Ö¼×¨Öµ××©Ö´××™×ª ×‘Ö¸Ö¼×¨Ö¸× ×Ö±×œÖ¹×”Ö´×™×"
- model: "hebrew"
- speed: 1.0
```

### 2. GeraÃ§Ã£o de Ãudio (TTS)
```
Sherpa-ONNX + MMS-TTS
â†’ audio_samples (numpy array)
â†’ Salva WAV temporÃ¡rio
â†’ DuraÃ§Ã£o: 2.45s
```

### 3. Forced Alignment (Whisper)
```
Whisper.transcribe()
- initial_prompt = texto original
- temperature = 0
- beam_size = 1
â†’ word_segments: [{'text': '...', 'start': ..., 'end': ...}]
```

### 4. Alinhamento (Fuzzy Matching)
```
fuzzy_match_words()
â†’ Normaliza tokens
â†’ Match sequencial
â†’ ConfianÃ§a por palavra
â†’ Fallback se necessÃ¡rio
```

### 5. Resposta JSON
```json
{
  "audio_base64": "...",
  "word_timestamps": [...],
  "alignment_stats": {...}
}
```

---

## ğŸ“Š Performance Esperada

### Oracle Free Tier (ARM64 CPU)

| Componente | Tempo | % |
|------------|-------|---|
| TTS | 0.1-0.3s | 15% |
| Whisper | 1.0-2.0s | 75% |
| Matching | 0.05-0.1s | 5% |
| Outros | 0.05-0.1s | 5% |
| **Total** | **1.2-2.5s** | **100%** |

**RTF:** ~0.5-1.0x (para 2-3s de Ã¡udio)

### Notebook Local (NVIDIA GPU)

| Componente | Tempo | % |
|------------|-------|---|
| TTS | 0.1-0.2s | 20% |
| Whisper | 0.3-0.6s | 60% |
| Matching | 0.05-0.1s | 15% |
| Outros | 0.05s | 5% |
| **Total** | **0.5-0.95s** | **100%** |

**RTF:** ~0.2-0.4x (mais rÃ¡pido que tempo real!)

---

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# VPS Oracle (ARM64 CPU)
WHISPER_MODEL=small
WHISPER_DEVICE=cpu
WHISPER_COMPUTE_TYPE=int8
WHISPER_CACHE_DIR=/app/.cache/whisper

# Notebook Local (NVIDIA GPU)
WHISPER_MODEL=medium
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16
WHISPER_CACHE_DIR=/app/.cache/whisper
```

### MemÃ³ria

- **CPU (small + int8):** ~500MB
- **GPU (medium + float16):** ~1.5GB VRAM

### AcurÃ¡cia

- **small:** 85-95% (hebraico/grego)
- **medium:** 90-98% (hebraico/grego)

---

## ğŸ¨ Casos de Uso

### 1. App de BÃ­blia - Highlight Sincronizado

```javascript
audio.addEventListener('timeupdate', () => {
  const currentTime = audio.currentTime;
  const currentWord = wordTimestamps.find(
    w => currentTime >= w.start && currentTime <= w.end
  );
  if (currentWord) {
    highlightVerse(currentWord.textStart, currentWord.textEnd);
  }
});
```

### 2. AnÃ¡lise de PronÃºncia

```python
low_confidence_words = [
    w for w in word_timestamps 
    if w['confidence'] < 0.7
]
print(f"Palavras com incerteza: {len(low_confidence_words)}")
```

### 3. GeraÃ§Ã£o de Legendas (SRT)

```python
def generate_srt(word_timestamps):
    for i, word in enumerate(word_timestamps, 1):
        start = format_timestamp(word['start'])
        end = format_timestamp(word['end'])
        print(f"{i}\n{start} --> {end}\n{word['text']}\n")
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [x] FunÃ§Ã£o `forced_align_audio_to_text()` em `word_alignment.py`
- [x] Endpoint `/speak_sync` em `multi_model_api.py`
- [x] InicializaÃ§Ã£o do Whisper no startup
- [x] DocumentaÃ§Ã£o completa (`FORCED_ALIGNMENT.md`)
- [x] Script de teste (`test_forced_alignment.py`)
- [x] Demo HTML interativo (`demo_forced_alignment.html`)
- [x] AtualizaÃ§Ã£o do README principal
- [x] Suporte a 3 idiomas (hebraico, grego, portuguÃªs)
- [x] Fallback para timestamps estimados
- [x] EstatÃ­sticas de qualidade de alinhamento
- [x] ConfiguraÃ§Ã£o via variÃ¡veis de ambiente

---

## ğŸ“š PrÃ³ximos Passos (Opcional)

### Melhorias Futuras

1. **Cache de alinhamentos**
   - Armazenar timestamps em cache
   - Evitar realinhamento do mesmo texto

2. **Suporte a mais idiomas**
   - Adicionar Ã¡rabe, latim, etc.
   - Mapa de cÃ³digos de idioma

3. **Fine-tuning do Whisper**
   - Treinar em corpus bÃ­blico
   - Melhorar acurÃ¡cia em nomes prÃ³prios

4. **Modo de alta precisÃ£o**
   - `beam_size > 1` opcional
   - `temperature > 0` com mÃºltiplas tentativas

5. **VisualizaÃ§Ã£o melhorada**
   - GrÃ¡fico de forma de onda
   - Espectrograma com marcadores

---

## ğŸ”— ReferÃªncias

- [faster-whisper Documentation](https://github.com/guillaumekln/faster-whisper)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx)
- [MMS-TTS Models](https://github.com/willwade/mms-tts-multilingual-models-onnx)

---

## ğŸ“ Notas TÃ©cnicas

### Por que `initial_prompt`?

O Whisper usa o `initial_prompt` como "dica" do que esperar no Ã¡udio. Ao passar o texto completo:
- âœ… Whisper tende a seguir o texto fornecido
- âœ… Reduz substituiÃ§Ãµes incorretas
- âœ… Melhora timestamps (sabe onde procurar)
- âš ï¸ NÃ£o Ã© 100% garantido (Whisper ainda pode variar)

Por isso usamos **fuzzy matching** para reconciliar variaÃ§Ãµes.

### Por que `temperature=0`?

- `temperature > 0`: Adiciona aleatoriedade (exploraÃ§Ã£o)
- `temperature = 0`: Sempre escolhe o token mais provÃ¡vel
- **Resultado:** SaÃ­da determinÃ­stica e reproduzÃ­vel

### Por que `beam_size=1`?

- `beam_size > 1`: Explora mÃºltiplos caminhos (mais lento)
- `beam_size = 1`: Busca gulosa (mais rÃ¡pido)
- **Resultado:** Menor latÃªncia, suficiente com `initial_prompt`

---

## ğŸ† ConclusÃ£o

A implementaÃ§Ã£o de forced alignment adiciona um recurso poderoso ao MMS-TTS API:

âœ… **Alinhamento palavra-por-palavra preciso**  
âœ… **Texto original como fonte da verdade**  
âœ… **Modo determinÃ­stico e reproduzÃ­vel**  
âœ… **Robusto com fallback inteligente**  
âœ… **Otimizado para CPU (Oracle Free Tier)**  
âœ… **DocumentaÃ§Ã£o completa e exemplos**  

Perfeito para apps de BÃ­blia, karaoke, aprendizado de idiomas e anÃ¡lise de fala! ğŸ‰
