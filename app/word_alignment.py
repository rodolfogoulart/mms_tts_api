"""
Word-level alignment module using faster-whisper
Otimizado para ARM64 CPU (Oracle VM.Standard.A1.Flex - 4 OCPUs, 24GB RAM)

Performance considerations:
- Modelo 'base' para melhor acur√°cia (vs 'tiny')
- int8 quantization para reduzir uso de mem√≥ria
- Explicitamente CPU-only (sem GPU overhead)
- Thread-safe para concorr√™ncia (2-3 requests simult√¢neos)
- Preserva Unicode (niqqud hebraico, acentos gregos)
"""

import os
import logging
import unicodedata
import re
import threading
from typing import List, Dict, Optional, Tuple
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)

# Cache directory for faster-whisper models
WHISPER_CACHE_DIR = os.getenv("WHISPER_CACHE_DIR", "/app/.cache/whisper")

# Global model instance (inicializado no startup da aplica√ß√£o)
_whisper_model = None
_model_lock = threading.Lock()  # Thread-safety para inicializa√ß√£o


def init_whisper_model():
    """
    Inicializa modelo faster-whisper no startup da aplica√ß√£o.
    Deve ser chamado UMA VEZ durante a inicializa√ß√£o do FastAPI.
    
    Performance:
    - Modelo 'base': ~150MB, melhor acur√°cia que 'tiny'
    - int8 compute: reduz mem√≥ria ~50% vs float16
    - num_workers=2: balanceado para 4 OCPUs ARM64
    - CPU-only: Oracle VM n√£o tem GPU
    
    Thread-safety: Usa lock para evitar inicializa√ß√£o duplicada
    """
    global _whisper_model
    
    with _model_lock:
        if _whisper_model is not None:
            logger.warning("Whisper model already initialized, skipping")
            return _whisper_model
        
        try:
            from faster_whisper import WhisperModel
            
            logger.info("üîß Initializing faster-whisper 'base' model (ARM64 CPU, int8)...")
            
            # Criar diret√≥rio de cache
            os.makedirs(WHISPER_CACHE_DIR, exist_ok=True)
            
            # Configura√ß√£o otimizada para ARM64 CPU (Oracle VM)
            _whisper_model = WhisperModel(
                "base",                    # Melhor acur√°cia que 'tiny' (~150MB)
                device="cpu",              # CPU-only (sem GPU overhead)
                compute_type="int8",       # Quantiza√ß√£o: menor mem√≥ria, boa performance
                download_root=WHISPER_CACHE_DIR,
                num_workers=2,             # 2 workers para 4 OCPUs (balanceado)
                cpu_threads=4              # 4 threads por worker (total 8 threads)
            )
            
            logger.info("‚úÖ faster-whisper 'base' model loaded successfully")
            logger.info(f"   - Device: CPU (ARM64)")
            logger.info(f"   - Compute: int8 quantization")
            logger.info(f"   - Workers: 2 (threads: 4 each)")
            
            return _whisper_model
            
        except ImportError as e:
            logger.error(f"‚ùå faster-whisper not installed: {e}")
            raise ImportError(
                "faster-whisper is required for word alignment. "
                "Install with: pip install faster-whisper"
            )
        except Exception as e:
            logger.error(f"‚ùå Error loading faster-whisper model: {e}")
            raise


def get_whisper_model():
    """
    Retorna inst√¢ncia do modelo Whisper (deve estar pr√©-inicializado).
    Raise exception se modelo n√£o foi inicializado no startup.
    """
    if _whisper_model is None:
        raise RuntimeError(
            "Whisper model not initialized. Call init_whisper_model() during app startup."
        )
    return _whisper_model


def normalize_for_matching(text: str) -> str:
    """
    Normaliza texto APENAS para matching fuzzy (n√£o para exibi√ß√£o)
    Remove acentos/diacr√≠ticos mas preserva estrutura das palavras
    """
    # Decompor caracteres Unicode (separar base + diacr√≠ticos)
    decomposed = unicodedata.normalize('NFD', text)
    
    # Remover apenas marcas diacr√≠ticas (categoria Mn = Nonspacing Mark)
    # Mant√©m letras base intactas
    base_text = ''.join(
        char for char in decomposed 
        if unicodedata.category(char) != 'Mn'
    )
    
    # Recompor e converter para min√∫sculas
    return unicodedata.normalize('NFC', base_text).lower()


def fuzzy_match_words(
    transcribed_words: List[str], 
    original_text: str,
    threshold: float = 0.4  # ‚Üê REDUZIDO de 0.5 para 0.4
) -> Tuple[List[str], List[float], List[Tuple[int, int]]]:
    """
    Faz matching avan√ßado entre palavras transcritas e texto original.
    Otimizado para hebraico/grego com algoritmo melhorado.
    
    Algoritmo:
    1. Separa palavras do texto original (preservando Unicode)
    2. Normaliza ambas as listas (remove diacr√≠ticos para compara√ß√£o)
    3. Para cada palavra transcrita:
       a. Busca melhor match em janela deslizante (EXPANDIDA para 10 palavras)
       b. Calcula similaridade com SequenceMatcher (Ratcliff-Obershelp)
       c. Aceita match se ratio >= threshold OU √© palavra sequencial
    4. Retorna palavras ORIGINAIS (com Unicode preservado)
    
    Performance:
    - Janela de 10 palavras: O(10n) ‚âà O(n) ainda aceit√°vel
    - SequenceMatcher √© otimizado em C (r√°pido)
    - Pre-normalization cache evita recomputa√ß√£o
    
    Args:
        transcribed_words: Palavras do Whisper (podem ter erros)
        original_text: Texto original com diacr√≠ticos
        threshold: Similaridade m√≠nima (0.0-1.0), padr√£o 0.4
    
    Returns:
        Tupla: (palavras matched, scores de confian√ßa, posi√ß√µes no texto)
    """
    # Separar palavras do texto original (preservando Unicode) COM POSI√á√ïES
    original_words = []
    word_positions = []
    
    for match in re.finditer(r'\S+', original_text):
        original_words.append(match.group())
        word_positions.append((match.start(), match.end()))
    
    if not original_words:
        logger.warning("Original text has no words")
        return [], [], []
    
    # Normalizar para matching (remove diacr√≠ticos)
    original_normalized = [normalize_for_matching(w) for w in original_words]
    transcribed_normalized = [normalize_for_matching(w) for w in transcribed_words]
    
    matched_words = []
    confidence_scores = []
    text_positions = []
    original_idx = 0
    
    # ‚Üê NOVO: Rastrear palavras j√° usadas para evitar duplicatas
    used_indices = set()
    
    for trans_idx, trans_word in enumerate(transcribed_normalized):
        best_match = None
        best_ratio = 0.0
        best_idx = original_idx
        
        # ‚Üê EXPANDIDO: Janela deslizante de 10 palavras (antes era 5)
        # Permite pular mais palavras se Whisper omitiu/adicionou
        search_start = max(0, original_idx - 2)  # ‚Üê NOVO: Olhar 2 palavras atr√°s tamb√©m
        search_end = min(len(original_normalized), original_idx + 10)
        
        for i in range(search_start, search_end):
            # ‚Üê NOVO: Pular palavras j√° usadas (evita duplicatas)
            if i in used_indices:
                continue
                
            orig_word = original_normalized[i]
            
            # Calcular similaridade (Ratcliff-Obershelp algorithm)
            ratio = SequenceMatcher(None, trans_word, orig_word).ratio()
            
            if ratio > best_ratio:
                best_ratio = ratio
                best_match = original_words[i]  # Palavra ORIGINAL (com Unicode)
                best_idx = i
        
        # ‚Üê AJUSTADO: Crit√©rio de aceita√ß√£o mais rigoroso
        # 1. Similaridade >= threshold (agora 40%)
        # 2. OU √© a pr√≥xima palavra sequencial (aceita mesmo com baixo score)
        # 3. OU √© a √∫nica palavra restante
        # 4. E N√ÉO foi usada ainda
        accept_match = (
            best_ratio >= threshold and 
            best_idx not in used_indices
        ) or (
            best_idx == original_idx and 
            best_idx not in used_indices
        ) or (
            original_idx >= len(original_words) - 1 and 
            best_idx not in used_indices
        )
        
        if accept_match and best_match:
            matched_words.append(best_match)
            confidence_scores.append(best_ratio)
            text_positions.append(word_positions[best_idx])
            used_indices.add(best_idx)  # ‚Üê NOVO: Marcar como usado
            original_idx = best_idx + 1
        else:
            # ‚Üê AJUSTADO: Fallback mais inteligente
            # Se confidence muito baixa (< 0.3), provavelmente √© ru√≠do do Whisper
            # N√£o adicionar ao resultado final
            if best_ratio < 0.3:
                logger.debug(f"Skipping low-confidence word: '{trans_word}' (score: {best_ratio:.2f})")
                continue
            
            # Fallback: usar palavra transcrita se tiver alguma similaridade
            fallback_word = transcribed_words[trans_idx] if trans_idx < len(transcribed_words) else trans_word
            matched_words.append(fallback_word)
            confidence_scores.append(best_ratio)
            text_positions.append((-1, -1))  # Posi√ß√£o desconhecida
            logger.debug(f"Low confidence match: '{trans_word}' -> '{fallback_word}' (score: {best_ratio:.2f})")
    
    # Log estat√≠sticas de matching
    if confidence_scores:
        avg_confidence = sum(confidence_scores) / len(confidence_scores)
        skipped = len(transcribed_words) - len(matched_words)
        logger.info(f"Matching complete: {len(matched_words)}/{len(transcribed_words)} words, "
                   f"avg confidence: {avg_confidence:.2f}, skipped: {skipped}")
    
    return matched_words, confidence_scores, text_positions


def align_words(audio_path: str, text: str, lang: str) -> List[Dict]:
    """
    Alinha palavras do √°udio com timestamps usando faster-whisper.
    
    Otimiza√ß√µes para ARM64:
    - Modelo 'base' pr√©-carregado (melhor acur√°cia)
    - beam_size=3 (balanceado: qualidade vs velocidade)
    - vad_filter=True (remove sil√™ncios, melhora acur√°cia)
    - language expl√≠cito (evita detec√ß√£o autom√°tica)
    - temperature=0.0 (determin√≠stico, sem varia√ß√£o)
    
    Graceful degradation:
    - NUNCA lan√ßa exce√ß√£o (retorna [] em caso de erro)
    - Log detalhado para debugging
    - Fallback se matching falhar
    
    Performance esperada (ARM64, 4 OCPUs):
    - √Åudio 3-5s: ~1.5-2.5s de processamento
    - √Åudio 10s: ~3-5s de processamento
    - Concorr√™ncia: suporta 2-3 requests simult√¢neos
    
    Args:
        audio_path: Caminho do arquivo MP3/WAV
        text: Texto original (com niqqud/acentos preservados)
        lang: C√≥digo de idioma MMS ('heb', 'ell', 'por')
    
    Returns:
        Lista: [{"text": "palavra", "start": 0.0, "end": 0.5, "textStart": 0, "textEnd": 7, "confidence": 0.95}, ...]
        Lista vazia [] se falhar (graceful degradation)
    """
    try:
        # Validar arquivo de √°udio
        if not os.path.exists(audio_path):
            logger.error(f"‚ùå Audio file not found: {audio_path}")
            return []
        
        # Obter modelo (deve estar pr√©-inicializado)
        try:
            model = get_whisper_model()
        except RuntimeError as e:
            logger.error(f"‚ùå {e}")
            return []
        
        # Mapear c√≥digo de idioma MMS -> Whisper ISO
        from .multi_model_api import WHISPER_LANG_MAP
        whisper_lang = WHISPER_LANG_MAP.get(lang, lang)
        
        logger.info(f"üéØ Starting word alignment: {os.path.basename(audio_path)} (lang: {whisper_lang})")
        
        # Transcrever com word-level timestamps
        # Configura√ß√£o otimizada para ARM64 CPU
        segments, info = model.transcribe(
            audio_path,
            language=whisper_lang,     # Expl√≠cito: evita detec√ß√£o autom√°tica (mais r√°pido)
            word_timestamps=True,      # Ativar timestamps por palavra
            vad_filter=True,           # Voice Activity Detection: remove sil√™ncios
            beam_size=3,               # Reduzido de 5: balanceado para CPU
            best_of=3,                 # Reduzido: menos candidates, mais r√°pido
            temperature=0.0,           # Determin√≠stico (greedy decoding)
            condition_on_previous_text=False,  # Independente: melhor para frases curtas
            compression_ratio_threshold=2.4,   # Detecta repeti√ß√µes
            log_prob_threshold=-1.0,           # Filtro de baixa confian√ßa
            no_speech_threshold=0.6            # Detecta sil√™ncio
        )
        
        # Extrair palavras com timestamps
        transcribed_words = []
        word_segments = []
        
        for segment in segments:
            if hasattr(segment, 'words') and segment.words:
                for word in segment.words:
                    word_text = word.word.strip()
                    if word_text:  # Ignorar vazios
                        transcribed_words.append(word_text)
                        word_segments.append({
                            'text': word_text,
                            'start': round(word.start, 2),
                            'end': round(word.end, 2),
                            'probability': getattr(word, 'probability', 1.0)
                        })
        
        if not word_segments:
            logger.warning(f"‚ö†Ô∏è  No words detected in audio: {audio_path}")
            return []
        
        logger.info(f"üìù Transcribed {len(transcribed_words)} words from Whisper")
        
        # Fazer fuzzy matching com texto original (preservar Unicode)
        matched_words, confidence_scores, text_positions = fuzzy_match_words(
            transcribed_words, 
            text,
            threshold=0.5  # 50% similaridade m√≠nima
        )
        
        # Combinar palavras matched com timestamps
        result = []
        for i, word_data in enumerate(word_segments):
            # Usar palavra original (com Unicode) se dispon√≠vel
            if i < len(matched_words):
                word_text = matched_words[i]
                match_confidence = confidence_scores[i] if i < len(confidence_scores) else 0.0
                text_start, text_end = text_positions[i] if i < len(text_positions) else (-1, -1)
            else:
                # Fallback: palavra transcrita
                word_text = word_data['text']
                match_confidence = 0.0
                text_start, text_end = -1, -1
            
            result.append({
                'text': word_text,
                'start': word_data['start'],
                'end': word_data['end'],
                'textStart': text_start,
                'textEnd': text_end,
                'confidence': round(match_confidence, 2)  # Adicionar score de confian√ßa
            })
        
        # Valida√ß√£o final
        if result:
            total_duration = result[-1]['end']
            avg_confidence = sum(w['confidence'] for w in result) / len(result)
            logger.info(f"‚úÖ Alignment complete: {len(result)} words, "
                       f"duration: {total_duration:.2f}s, "
                       f"avg confidence: {avg_confidence:.2f}")
        return result
        
    except ImportError as e:
        logger.error(f"‚ùå faster-whisper not available: {e}")
        return []
    except Exception as e:
        # CR√çTICO: NUNCA lan√ßar exce√ß√£o (graceful degradation)
        logger.error(f"‚ùå Error during word alignment: {e}", exc_info=True)
        return []


def validate_alignment(words: List[Dict], audio_duration: float) -> bool:
    """
    Valida se o alinhamento √© razo√°vel
    
    Args:
        words: Lista de palavras com timestamps
        audio_duration: Dura√ß√£o do √°udio em segundos
    
    Returns:
        True se alinhamento parece v√°lido
    """
    if not words:
        return False
    
    # Verificar se timestamps est√£o dentro da dura√ß√£o
    last_word_end = words[-1]['end']
    if last_word_end > audio_duration * 1.2:  # Toler√¢ncia de 20%
        logger.warning(f"Last word timestamp ({last_word_end}s) exceeds audio duration ({audio_duration}s)")
        return False
    
    # Verificar se timestamps est√£o em ordem crescente
    for i in range(len(words) - 1):
        if words[i]['end'] > words[i + 1]['start']:
            logger.warning(f"Word timestamps not in order: {words[i]} -> {words[i+1]}")
            return False
    
    return True
