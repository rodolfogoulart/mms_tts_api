# Forced Alignment - Guia de Uso

## üìñ Vis√£o Geral

O endpoint `/speak_sync` implementa **forced alignment** palavra-por-palavra, combinando:

1. **MMS-TTS (Sherpa-ONNX)**: Gera√ß√£o de √°udio de alta qualidade
2. **Whisper**: Alinhamento temporal (n√£o reconhecimento)

O texto fornecido √© a **√öNICA FONTE DA VERDADE**. O Whisper √© usado apenas para obter timestamps precisos, n√£o para reconhecer ou corrigir o texto.

---

## üéØ Caracter√≠sticas

### ‚úÖ Modo Determin√≠stico
- `temperature = 0` (sem aleatoriedade)
- `beam_size = 1` (busca determin√≠stica)
- `initial_prompt = texto original` (for√ßa Whisper a seguir o texto)

### ‚úÖ Alinhamento Robusto
- Normaliza√ß√£o multil√≠ngue (hebraico, grego, portugu√™s)
- Fuzzy matching para reconciliar pequenas varia√ß√µes
- Fallback para timestamps estimados se alinhamento falhar

### ‚úÖ Otimizado para CPU
- Configura√ß√£o via vari√°veis de ambiente
- Modelo Whisper 'small' para Oracle Free Tier
- int8 compute type para economia de mem√≥ria

---

## üì° Endpoint: POST `/speak_sync`

### Par√¢metros

| Par√¢metro | Tipo | Obrigat√≥rio | Padr√£o | Descri√ß√£o |
|-----------|------|-------------|--------|-----------|
| `text` | string | ‚úÖ Sim | - | Texto original (hebraico, grego ou portugu√™s) |
| `model` | string | ‚ùå N√£o | `hebrew` | Modelo TTS: `hebrew`, `greek`, `portuguese` |
| `speed` | float | ‚ùå N√£o | `1.0` | Velocidade da fala (0.5 a 2.0) |
| `output_format` | string | ‚ùå N√£o | `mp3` | Formato do √°udio: `mp3` ou `wav` |
| `return_audio` | bool | ‚ùå N√£o | `true` | Se `true`, retorna √°udio em base64; se `false`, salva em cache |

### Exemplo de Requisi√ß√£o

```bash
curl -X POST "http://localhost:8000/speak_sync" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "text=◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™ ◊ë÷∏÷º◊®÷∏◊ê ◊ê÷±◊ú÷π◊î÷¥◊ô◊ù" \
  -d "model=hebrew" \
  -d "speed=1.0" \
  -d "output_format=mp3" \
  -d "return_audio=true"
```

### Resposta JSON

```json
{
  "text": "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™ ◊ë÷∏÷º◊®÷∏◊ê ◊ê÷±◊ú÷π◊î÷¥◊ô◊ù",
  "model": "hebrew",
  "speed": 1.0,
  "audio_duration": 2.45,
  "audio_format": "mp3",
  "audio_base64": "SUQzBAAAAAAAI1RTU0UAAAA...",
  "word_timestamps": [
    {
      "text": "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™",
      "start": 0.0,
      "end": 0.82,
      "textStart": 0,
      "textEnd": 9,
      "confidence": 1.0
    },
    {
      "text": "◊ë÷∏÷º◊®÷∏◊ê",
      "start": 0.82,
      "end": 1.24,
      "textStart": 10,
      "textEnd": 14,
      "confidence": 0.98
    },
    {
      "text": "◊ê÷±◊ú÷π◊î÷¥◊ô◊ù",
      "start": 1.24,
      "end": 2.45,
      "textStart": 15,
      "textEnd": 21,
      "confidence": 1.0
    }
  ],
  "alignment_stats": {
    "total_words": 3,
    "matched_words": 3,
    "match_ratio": 1.0
  },
  "processing_time": {
    "tts_seconds": 0.15,
    "alignment_seconds": 1.23,
    "total_seconds": 1.38
  }
}
```

---

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

Configure o comportamento do Whisper:

```bash
# Modelo Whisper (small para VPS, medium para local)
WHISPER_MODEL=small

# Dispositivo (cpu para VPS, cuda para GPU)
WHISPER_DEVICE=cpu

# Tipo de computa√ß√£o (int8 para CPU, float16 para GPU)
WHISPER_COMPUTE_TYPE=int8

# Diret√≥rio de cache dos modelos
WHISPER_CACHE_DIR=/app/.cache/whisper
```

### Configura√ß√µes Recomendadas

#### Oracle Free Tier (ARM64 CPU)
```bash
WHISPER_MODEL=small
WHISPER_DEVICE=cpu
WHISPER_COMPUTE_TYPE=int8
```

**Performance esperada:**
- Mem√≥ria: ~500MB
- Acur√°cia: 85-95% (hebraico/grego)
- RTF: ~1.0-1.5x (tempo real)

#### Notebook Local (NVIDIA GPU)
```bash
WHISPER_MODEL=medium
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16
```

**Performance esperada:**
- VRAM: ~1.5GB
- Acur√°cia: 90-98%
- RTF: ~0.3-0.5x (mais r√°pido que tempo real)

---

## üß™ Testes

### Python
```python
import requests
import json
import base64

url = "http://localhost:8000/speak_sync"
data = {
    "text": "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™ ◊ë÷∏÷º◊®÷∏◊ê ◊ê÷±◊ú÷π◊î÷¥◊ô◊ù",
    "model": "hebrew",
    "speed": 1.0,
    "output_format": "mp3",
    "return_audio": True
}

response = requests.post(url, data=data)
result = response.json()

print(f"Duration: {result['audio_duration']}s")
print(f"Words: {result['alignment_stats']['total_words']}")
print(f"Match ratio: {result['alignment_stats']['match_ratio']:.1%}")

# Salvar √°udio
if 'audio_base64' in result:
    audio_bytes = base64.b64decode(result['audio_base64'])
    with open('output.mp3', 'wb') as f:
        f.write(audio_bytes)
    print("Audio saved to output.mp3")

# Imprimir timestamps
for word in result['word_timestamps']:
    print(f"{word['text']}: {word['start']:.2f}s - {word['end']:.2f}s")
```

### JavaScript (Fetch)
```javascript
const formData = new URLSearchParams();
formData.append('text', '◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™ ◊ë÷∏÷º◊®÷∏◊ê ◊ê÷±◊ú÷π◊î÷¥◊ô◊ù');
formData.append('model', 'hebrew');
formData.append('speed', '1.0');
formData.append('output_format', 'mp3');
formData.append('return_audio', 'true');

fetch('http://localhost:8000/speak_sync', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/x-www-form-urlencoded',
  },
  body: formData
})
.then(response => response.json())
.then(data => {
  console.log(`Duration: ${data.audio_duration}s`);
  console.log(`Words: ${data.alignment_stats.total_words}`);
  console.log(`Match ratio: ${data.alignment_stats.match_ratio}`);
  
  // Criar elemento de √°udio
  const audioSrc = `data:audio/mp3;base64,${data.audio_base64}`;
  const audio = new Audio(audioSrc);
  
  // Highlight palavra-por-palavra
  data.word_timestamps.forEach(word => {
    setTimeout(() => {
      console.log(`Highlighting: ${word.text}`);
      // Seu c√≥digo de highlight aqui
    }, word.start * 1000);
  });
  
  audio.play();
});
```

---

## üìä Estrutura do Output

### `word_timestamps[]`

Cada elemento cont√©m:

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `text` | string | Palavra original exata (com pontua√ß√£o e diacr√≠ticos) |
| `start` | float | Timestamp de in√≠cio (segundos) |
| `end` | float | Timestamp de fim (segundos) |
| `textStart` | int | √çndice do primeiro caractere no texto original |
| `textEnd` | int | √çndice ap√≥s o √∫ltimo caractere |
| `confidence` | float | Confian√ßa do alinhamento (0.0 a 1.0) |

**Observa√ß√µes:**
- `confidence = 1.0`: Match exato
- `confidence >= 0.55`: Match fuzzy confi√°vel
- `confidence = 0.3`: Timestamp estimado (fallback)
- `confidence = 0.0`: Sem timestamp (palavra n√£o matched)

### `alignment_stats`

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `total_words` | int | Total de palavras no texto original |
| `matched_words` | int | Palavras com timestamps confi√°veis |
| `match_ratio` | float | Percentual de palavras matched (0.0 a 1.0) |

---

## üé® Casos de Uso

### 1. Highlight Palavra-por-Palavra em App de B√≠blia
```javascript
// Sincronizar highlight com √°udio
audio.addEventListener('timeupdate', () => {
  const currentTime = audio.currentTime;
  const currentWord = wordTimestamps.find(
    w => currentTime >= w.start && currentTime <= w.end
  );
  
  if (currentWord) {
    highlightWord(currentWord.textStart, currentWord.textEnd);
  }
});
```

### 2. An√°lise de Pron√∫ncia
```python
# Identificar palavras com baixa confian√ßa
low_confidence_words = [
    w for w in word_timestamps 
    if w['confidence'] < 0.7
]

print(f"Words with timing uncertainty: {len(low_confidence_words)}")
for word in low_confidence_words:
    print(f"  - {word['text']} (confidence: {word['confidence']:.2f})")
```

### 3. Gera√ß√£o de Legendas (SRT)
```python
def generate_srt(word_timestamps):
    srt_content = []
    for i, word in enumerate(word_timestamps, 1):
        start = format_timestamp(word['start'])
        end = format_timestamp(word['end'])
        srt_content.append(f"{i}\n{start} --> {end}\n{word['text']}\n")
    return "\n".join(srt_content)

def format_timestamp(seconds):
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
```

---

## ‚ö†Ô∏è Troubleshooting

### Erro: "Word alignment feature not available"
**Causa:** `faster-whisper` n√£o instalado

**Solu√ß√£o:**
```bash
pip install faster-whisper
```

### Baixa qualidade de alinhamento (match_ratio < 0.5)
**Causas poss√≠veis:**
- √Åudio com ru√≠do ou baixa qualidade
- Velocidade muito r√°pida (`speed > 1.5`)
- Idioma incorreto

**Solu√ß√µes:**
1. Reduzir velocidade: `speed=1.0`
2. Verificar modelo correto: `model=hebrew/greek/portuguese`
3. Usar modelo Whisper maior: `WHISPER_MODEL=medium`

### Timestamps imprecisos
**Causa:** Fallback para estimativa (match_ratio < 0.5)

**Identifica√ß√£o:**
```python
if result['alignment_stats']['match_ratio'] < 0.5:
    print("‚ö†Ô∏è  Using estimated timestamps (low alignment quality)")
```

**Solu√ß√£o:**
- Melhorar qualidade do √°udio de entrada
- Usar `normalize_audio=True` (padr√£o)

---

## üöÄ Performance

### Tempos Esperados (Oracle Free Tier)

| Componente | Tempo | % Total |
|------------|-------|---------|
| TTS (Sherpa-ONNX) | 0.1-0.3s | 10-20% |
| Whisper Transcription | 1.0-2.0s | 70-80% |
| Fuzzy Matching | 0.05-0.1s | 5-10% |
| **Total** | **1.2-2.5s** | **100%** |

**RTF (Real-Time Factor):** ~0.5-1.0x (para 2-3s de √°udio)

---

## üìù Notas T√©cnicas

### Diferen√ßas vs ASR Tradicional
| Aspecto | ASR Tradicional | Forced Alignment |
|---------|-----------------|------------------|
| Objetivo | Reconhecer texto | Obter timestamps |
| Texto de entrada | ‚ùå N√£o usa | ‚úÖ Fonte da verdade |
| Corre√ß√£o de texto | ‚úÖ Sim | ‚ùå N√£o (mant√©m original) |
| `initial_prompt` | Contexto opcional | **Texto completo** |
| Output | Texto transcrito | Timestamps + texto original |

### Normaliza√ß√£o Multil√≠ngue
O fuzzy matching remove:
- **Hebraico:** Niqqud (◊†÷¥◊ß÷º◊ï÷º◊ì), Cantillation marks
- **Grego:** Acentos (Œ¨, Œ≠, œå), esp√≠ritos (·ºÄ, ·ºÅ)
- **Portugu√™s:** Acentos (√°, √™, √ß)

Isso permite matching robusto mesmo com pequenas varia√ß√µes do Whisper.

---

## üìö Refer√™ncias

- [faster-whisper](https://github.com/guillaumekln/faster-whisper)
- [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx)
- [OpenAI Whisper](https://github.com/openai/whisper)

---

## üìÑ Licen√ßa

Este projeto usa:
- MMS-TTS (Meta): CC-BY-NC 4.0
- Whisper (OpenAI): MIT License
